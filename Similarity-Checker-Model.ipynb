{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa65060-b239-4174-849b-370e49140da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\TravelMate\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "import nltk\n",
    "nltk.download(\"popular\")\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e055622e-4466-4089-a736-9b0535bda735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_text</th>\n",
       "      <th>plagiarized_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ANewHybridTechniqueforDetectionofPlagiarismfro...</td>\n",
       "      <td>Plagiarism occurs when we use the ideas, expr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Current Status, Challenges, and Opportunities ...</td>\n",
       "      <td>rice staple food nearly half worlds population...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Meeting the challenges of global rice production</td>\n",
       "      <td>rice is the second most widely grown cereal cr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>An overview of global rice production, supply,...</td>\n",
       "      <td>rice is the staple food for over half the worl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Current Status and Challenges of Rice Producti...</td>\n",
       "      <td>rice production in china has more than tripled...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        source_text  \\\n",
       "0           0  ANewHybridTechniqueforDetectionofPlagiarismfro...   \n",
       "1           1  Current Status, Challenges, and Opportunities ...   \n",
       "2           2   Meeting the challenges of global rice production   \n",
       "3           3  An overview of global rice production, supply,...   \n",
       "4           4  Current Status and Challenges of Rice Producti...   \n",
       "\n",
       "                                    plagiarized_text  label  \n",
       "0   Plagiarism occurs when we use the ideas, expr...      1  \n",
       "1  rice staple food nearly half worlds population...      1  \n",
       "2  rice is the second most widely grown cereal cr...      1  \n",
       "3  rice is the staple food for over half the worl...      1  \n",
       "4  rice production in china has more than tripled...      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Dataset\n",
    "data = pd.read_csv(\"dataset2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fef6610-840f-4924-879b-a07a76b1bb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    187\n",
       "1    183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcf4fb32-d4a6-482b-b1b1-59447bc3b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean text\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = \" \".join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "data[\"source_text\"] = data[\"source_text\"].apply(preprocess_text)\n",
    "data[\"plagiarized_text\"] = data[\"plagiarized_text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6e90987-bada-454d-9e52-0383ee9f6e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_text</th>\n",
       "      <th>plagiarized_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>anewhybridtechniquefordetectionofplagiarismfro...</td>\n",
       "      <td>plagiarism occurs use ideas expressions work w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>current status challenges opportunities rice p...</td>\n",
       "      <td>rice staple food nearly half worlds population...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>meeting challenges global rice production</td>\n",
       "      <td>rice second widely grown cereal crop staple fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>overview global rice production supply trade c...</td>\n",
       "      <td>rice staple food half worlds population approx...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>current status challenges rice production china</td>\n",
       "      <td>rice production china tripled past five decade...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>397</td>\n",
       "      <td>playing musical instruments enhances creativity</td>\n",
       "      <td>creativity enhanced playing musical instruments</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>398</td>\n",
       "      <td>studying history helps understanding present</td>\n",
       "      <td>understanding present aided studying history</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>399</td>\n",
       "      <td>listening classical music improve focus</td>\n",
       "      <td>focus improved listening classical music</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>400</td>\n",
       "      <td>practicing yoga enhances physical flexibility</td>\n",
       "      <td>physical flexibility enhanced practicing yoga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>401</td>\n",
       "      <td>volunteering fosters community spirit</td>\n",
       "      <td>community spirit fostered volunteering</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                        source_text  \\\n",
       "0             0  anewhybridtechniquefordetectionofplagiarismfro...   \n",
       "1             1  current status challenges opportunities rice p...   \n",
       "2             2          meeting challenges global rice production   \n",
       "3             3  overview global rice production supply trade c...   \n",
       "4             4    current status challenges rice production china   \n",
       "..          ...                                                ...   \n",
       "365         397    playing musical instruments enhances creativity   \n",
       "366         398       studying history helps understanding present   \n",
       "367         399            listening classical music improve focus   \n",
       "368         400      practicing yoga enhances physical flexibility   \n",
       "369         401              volunteering fosters community spirit   \n",
       "\n",
       "                                      plagiarized_text  label  \n",
       "0    plagiarism occurs use ideas expressions work w...      1  \n",
       "1    rice staple food nearly half worlds population...      1  \n",
       "2    rice second widely grown cereal crop staple fo...      1  \n",
       "3    rice staple food half worlds population approx...      1  \n",
       "4    rice production china tripled past five decade...      1  \n",
       "..                                                 ...    ...  \n",
       "365    creativity enhanced playing musical instruments      0  \n",
       "366       understanding present aided studying history      0  \n",
       "367           focus improved listening classical music      0  \n",
       "368      physical flexibility enhanced practicing yoga      0  \n",
       "369             community spirit fostered volunteering      0  \n",
       "\n",
       "[370 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8de76b74-38ba-42fe-99a6-124f4f334d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(data[\"source_text\"] + \" \" + data[\"plagiarized_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "901d9b8b-a858-4bc1-a848-28c72db68c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ed47e0d-1800-433f-8707-525323f9ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92877e26-1216-426b-9f2d-ad9b5d6df2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8513513513513513\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85        35\n",
      "           1       0.89      0.82      0.85        39\n",
      "\n",
      "    accuracy                           0.85        74\n",
      "   macro avg       0.85      0.85      0.85        74\n",
      "weighted avg       0.85      0.85      0.85        74\n",
      "\n",
      "Confusion Matrix\n",
      "[[31  4]\n",
      " [ 7 32]]\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8ef2e54-27f5-4d29-bc1b-4811d2ca2607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8378378378378378\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85        35\n",
      "           1       0.97      0.72      0.82        39\n",
      "\n",
      "    accuracy                           0.84        74\n",
      "   macro avg       0.86      0.84      0.84        74\n",
      "weighted avg       0.87      0.84      0.84        74\n",
      "\n",
      "Confusion Matrix:\n",
      "[[34  1]\n",
      " [11 28]]\n"
     ]
    }
   ],
   "source": [
    "#random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Generate classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ba18b7c-1a77-4ff7-9c42-ab77932fed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8648648648648649\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        35\n",
      "           1       0.87      0.87      0.87        39\n",
      "\n",
      "    accuracy                           0.86        74\n",
      "   macro avg       0.86      0.86      0.86        74\n",
      "weighted avg       0.86      0.86      0.86        74\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30  5]\n",
      " [ 5 34]]\n"
     ]
    }
   ],
   "source": [
    "#naiv bays model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Instantiate the model\n",
    "model = MultinomialNB()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Generate classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aaaed40e-949f-44f1-9c9f-7c82eda3b008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.918918918918919\n",
      "Best Parameters: {'C': 10, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92        37\n",
      "           1       0.97      0.86      0.91        37\n",
      "\n",
      "    accuracy                           0.92        74\n",
      "   macro avg       0.92      0.92      0.92        74\n",
      "weighted avg       0.92      0.92      0.92        74\n",
      "\n",
      "Confusion Matrix:\n",
      "[[36  1]\n",
      " [ 5 32]]\n",
      "Cross-validated Accuracy: 0.908108108108108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: TF-IDF Vectorization with optimal settings\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000, stop_words='english')\n",
    "X = tfidf_vectorizer.fit_transform(data[\"source_text\"] + \" \" + data[\"plagiarized_text\"])\n",
    "y = data[\"label\"]\n",
    "\n",
    "# Step 2: Train-Test Split (stratified to maintain class distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Step 3: Hyperparameter Tuning with GridSearchCV (Linear + RBF kernels)\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear'],  # Stick to linear for sparse data\n",
    "    'class_weight': ['balanced', None]  # Handle class imbalance\n",
    "}\n",
    "\n",
    "# Use StratifiedKFold for better cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Get the best model and make predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Step 6: Print Results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Step 7: Cross-Validation for Stability Check\n",
    "cross_val_scores = cross_val_score(best_model, X, y, cv=cv, scoring='accuracy')\n",
    "print(\"Cross-validated Accuracy:\", cross_val_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0a6a94f-bb52-4367-b569-e815569fddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save SVM and Vectorizor\n",
    "import pickle\n",
    "\n",
    "pickle.dump(model,open(\"model.pkl\",'wb'))\n",
    "pickle.dump(tfidf_vectorizer, open('tfidf_vectorizer.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3eecc12f-d553-40e6-bd46-b0023c070e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model and Vectorizer\n",
    "model = pickle.load(open('model.pkl','rb'))\n",
    "tfidf_vectorizer = pickle.load(open('tfidf_vectorizer.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a823188-5be6-4f6d-9eb8-2c0cb3958b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detection System\n",
    "def detect(input_text):\n",
    "    vectorized_text = tfidf_vectorizer.transform([input_text])\n",
    "    result = model.predict(vectorized_text)\n",
    "    return \"Plagiarim Detected\" if result[0] == 1 else \"No Plagiarism\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2463360-b5fa-4ee9-9eaa-c70ece566407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plagiarism Detected'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example ( it is a plagarized text)\n",
    "input_text = 'rice staple food nearly half worlds population continued increased production meet enhanced demand due everincreasing population faces many challenges per capita availability land water increasing fast rate worldwide mass ruraltourban movement youth search better livelihood reducing availability farm labor rice going suffer due changes high water labor requirements development highyielding varietieshybrids rice concomitant use high levels fertilizer specially nitrogen two major drivers increased rice production last four decades overuse fertilizer nitrogen created environmental problems greenhouse warming depletion ozone layer eutrophication surface groundwaters global concern nitrogen application rates rice therefore reduced may affect production nitrogen use efficiency rice lowest among cereals therefore urgent need developing nitrogen useefficient varieties rice production technologies demanding lesser water labor nitrogen pesticides achieving going herculean task agricultural scientists'\n",
    "detect(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c9db853-a616-4ca1-8eda-a3f746b9a061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No Plagiarism'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example ( it has no plagiarism)\n",
    "input_text = 'Caffeine is contained in coffee.'\n",
    "detect(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80a1013f-d706-4003-ae5b-05da8ce5e09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plagiarism Detected\n"
     ]
    }
   ],
   "source": [
    "# Ensure correct saving of the model and vectorizer\n",
    "import pickle\n",
    "\n",
    "# Save the best model and vectorizer\n",
    "with open(\"model.pkl\", 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "# Load the saved model and vectorizer correctly\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "# Detection system function\n",
    "def detect(input_text):\n",
    "    # Ensure input text is vectorized with the loaded vectorizer\n",
    "    vectorized_text = tfidf_vectorizer.transform([input_text])\n",
    "    result = model.predict(vectorized_text)\n",
    "    return \"Plagiarism Detected\" if result[0] == 1 else \"No Plagiarism\"\n",
    "\n",
    "# Example input (plagiarized text)\n",
    "input_text = (\n",
    "    'rice staple food nearly half worlds population continued increased '\n",
    "    'production meet enhanced demand due everincreasing population faces '\n",
    "    'many challenges per capita availability land water increasing fast rate...'\n",
    ")\n",
    "\n",
    "# Run the detection function\n",
    "print(detect(input_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54021098-965b-4502-96d4-addedae4a2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c21208-4510-46c6-a59d-97bf0463b91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
